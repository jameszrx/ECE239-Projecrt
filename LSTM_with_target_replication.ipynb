{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM with target replication.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "4FU8lKg0pbPe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 10
            }
          ],
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "30e14cdd-88a6-492d-ecc2-344deb96fa4d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521001126823,
          "user_tz": 420,
          "elapsed": 1278030,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-804e0fb6-35bb-466e-abc8-9966427bc88c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-804e0fb6-35bb-466e-abc8-9966427bc88c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving A01T_slice.mat to A01T_slice.mat\n",
            "Saving A02T_slice.mat to A02T_slice.mat\n",
            "Saving A03T_slice.mat to A03T_slice.mat\n",
            "Saving A04T_slice.mat to A04T_slice.mat\n",
            "Saving A05T_slice.mat to A05T_slice.mat\n",
            "Saving A06T_slice.mat to A06T_slice.mat\n",
            "Saving A07T_slice.mat to A07T_slice.mat\n",
            "Saving A08T_slice.mat to A08T_slice.mat\n",
            "Saving A09T_slice.mat to A09T_slice.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x6QcdL-9pbPj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import rnn, rnn_cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEhapYq0pbPm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def one_hot(i):\n",
        "    a = [0,0,0,0]\n",
        "    a[i-769] = 1;\n",
        "    return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSSYFoN0pbPr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load subject data and store the reshaped data in X_sub[i], y_sub[i] \n",
        "X_sub = []\n",
        "y_sub = []\n",
        "for i in np.arange(9):\n",
        "    data = h5py.File('A0'+str(i+1)+'T_slice.mat', 'r')\n",
        "    X_sub.append(np.copy(data['image']))\n",
        "    y_sub.append(np.copy(data['type']))\n",
        "    X_sub[i] = X_sub[i][:, :22, :]\n",
        "    X_sub[i] = X_sub[i].transpose([0,2,1])\n",
        "    y_sub[i] = y_sub[i][0,0:X_sub[i].shape[0]:1]\n",
        "    y_sub[i] = np.asarray(y_sub[i], dtype=np.int32)\n",
        "    y_sub[i] = [one_hot(j) for j in y_sub[i]]\n",
        "    y_sub[i] = np.asarray(y_sub[i], dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SqV-uEdIpbPt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Remove NaN\n",
        "for i in np.arange(9):\n",
        "    y_sub[i] = y_sub[i][~np.isnan(X_sub[i]).any(axis=(1,2))]\n",
        "    X_sub[i] = X_sub[i][~np.isnan(X_sub[i]).any(axis=(1,2))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFYm0ucFpbPv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Data Normalization\n",
        "def normalize(dataset):\n",
        "    mu = np.mean(dataset,axis=0)\n",
        "    sigma = np.std(dataset,axis=0)\n",
        "    return (dataset - mu)/ sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuKLuN1LpbPx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "40d33d67-a705-407e-ca66-898e94fb1682",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521001293711,
          "user_tz": 420,
          "elapsed": 3027,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For training across all subjects\n",
        "# Shuffle the data, sample 20% for testing, and the rest for training\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "X = np.concatenate([X_sub[i] for i in np.arange(9)])\n",
        "y = np.concatenate([y_sub[i] for i in np.arange(9)])\n",
        "num_trial = X.shape[0]\n",
        "index_shuffle = np.arange(num_trial)\n",
        "np.random.shuffle(index_shuffle)\n",
        "X_shuffle = X[index_shuffle]\n",
        "y_shuffle = y[index_shuffle]\n",
        "\n",
        "training_index = int(np.floor(num_trial * (1 - 0.2)))\n",
        "#validation_index = training_index + int(np.floor(num_trial * 0.2))\n",
        "# test_index = num_trial\n",
        "\n",
        "X_train = X_shuffle[0:training_index]\n",
        "y_train = y_shuffle[0:training_index]\n",
        "# X_val = X_shuffle[training_index:validation_index]\n",
        "# y_val = y_shuffle[training_index:validation_index]\n",
        "# y_val_steps = np.tile(y_val,((X_train.shape[1]),1))\n",
        "X_test = X_shuffle[training_index:num_trial]\n",
        "y_test = y_shuffle[training_index:num_trial]\n",
        "y_test_steps = np.tile(y_test,((X_train.shape[1]),1))\n",
        "\n",
        "X_train = normalize(X_train)\n",
        "#X_val = normalize(X_val)\n",
        "X_test = normalize(X_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test_steps.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2046, 1000, 22)\n",
            "(512, 1000, 22)\n",
            "(512000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uF_x873MpbP3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "161a4a41-bedd-41d5-e479-46ab4625b2a7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521001297467,
          "user_tz": 420,
          "elapsed": 1478,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For training within each subject[i]\n",
        "# Shuffle the data, sample 50 trials for testing, and the rest for training -->\n",
        "X_train_sub = []\n",
        "y_train_sub = []\n",
        "X_test_sub = []\n",
        "y_test_sub = []\n",
        "y_test_steps_sub = []\n",
        "\n",
        "for i in np.arange(9):\n",
        "    num_trial_sub = X_sub[i].shape[0]\n",
        "    index_shuffle_sub = np.arange(num_trial_sub)\n",
        "    np.random.shuffle(index_shuffle_sub)\n",
        "    X_shuffle_sub = X_sub[i][index_shuffle_sub]\n",
        "    y_shuffle_sub = y_sub[i][index_shuffle_sub]\n",
        "    \n",
        "    training_index_sub = num_trial_sub - 50\n",
        "    \n",
        "    X_train_sub.append(X_shuffle_sub[0:training_index_sub])\n",
        "    y_train_sub.append(y_shuffle_sub[0:training_index_sub])\n",
        "    X_test_sub.append(X_shuffle[training_index_sub:num_trial_sub])\n",
        "    y_test_sub.append(y_shuffle[training_index_sub:num_trial_sub])\n",
        "    y_test_steps_sub.append(np.tile(y_test_sub[i],((X_train_sub[i].shape[1]),1)))\n",
        "\n",
        "    X_train_sub[i] = normalize(X_train_sub[i])\n",
        "    X_test_sub[i] = normalize(X_test_sub[i])\n",
        "\n",
        "    print(X_train_sub[i].shape)\n",
        "    print(X_test_sub[i].shape)\n",
        "    print(y_test_steps_sub[i].shape)    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(237, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(236, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(236, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(234, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(232, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(235, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(238, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(232, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n",
            "(228, 1000, 22)\n",
            "(50, 1000, 22)\n",
            "(50000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9MJ4UCMZpbP6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For training across all subjects: Hyperparameters setting\n",
        "tf.reset_default_graph()\n",
        "\n",
        "learning_rate = 0.0001\n",
        "training_epochs = 30\n",
        "batch_size = 35\n",
        "total_batches = (X_train.shape[0]//batch_size)\n",
        "# print(total_batches)\n",
        "\n",
        "alpha = 0.3\n",
        "reg = 1\n",
        "\n",
        "# Common parameters\n",
        "n_hidden = 64\n",
        "n_layers = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzxBpy-spbP8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For training within each subject: Hyperparameters setting\n",
        "tf.reset_default_graph()\n",
        "\n",
        "learning_rate_sub = 0.001\n",
        "training_epochs_sub = 10\n",
        "batch_size_sub = 15\n",
        "total_batches_sub = (X_train_sub[i].shape[0]//batch_size_sub)\n",
        "# print(total_batches)\n",
        "\n",
        "alpha_sub = 0.3\n",
        "reg_sub = 1\n",
        "\n",
        "# Common parameters\n",
        "n_hidden = 128\n",
        "n_layers = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8iXFiPcpbP_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Fixed Parameters\n",
        "n_input = 22\n",
        "n_steps = 1000\n",
        "n_classes = 4\n",
        "\n",
        "\n",
        "# Placeholders\n",
        "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "y_steps = tf.placeholder(\"float\", [None, n_classes])\n",
        "dropout = tf.placeholder(tf.float32) # prob to drop the cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhLsU1irpbQC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.0, shape = shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def LSTM(x, weight, bias):\n",
        "    cells = []\n",
        "    for i in np.arange(n_layers):\n",
        "        cell = rnn_cell.LSTMCell(n_hidden,state_is_tuple = True)\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(\n",
        "            cell, output_keep_prob=1.0 - dropout)\n",
        "        cells.append(cell)\n",
        "    multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
        "    output, state = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype = tf.float32)\n",
        "    output_flattened = tf.reshape(output, [-1, n_hidden])\n",
        "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
        "    output_all = tf.nn.sigmoid(output_logits)\n",
        "    output_reshaped = tf.reshape(output_all,[-1,n_steps,n_classes])\n",
        "    output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), n_steps - 1)  \n",
        "\n",
        "    return output_last, output_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDxmnbxkpbQE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "weight = weight_variable([n_hidden,n_classes])\n",
        "bias = bias_variable([n_classes])\n",
        "y_last, y_all = LSTM(x,weight,bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbJKTbr1pbQJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f94bcea1-3989-46cb-d98b-8dd43f427c6d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521006843881,
          "user_tz": 420,
          "elapsed": 2219,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "all_steps_cost = -tf.reduce_mean((y_steps * tf.log(y_all))  + (1 - y_steps) * tf.log(1 - y_all))\n",
        "last_step_cost = -tf.reduce_mean((y * tf.log(y_last)) + ((1 - y) * tf.log(1 - y_last)))\n",
        "regularizer = tf.nn.l2_loss(weight)\n",
        "loss_function = (alpha * all_steps_cost) + ((1 - alpha) * last_step_cost) + reg * 0.5 *  regularizer\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y_last, axis = 1),tf.argmax(y,axis = 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Il9JLVNRpbQN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 64
            },
            {
              "item_id": 128
            },
            {
              "item_id": 150
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 2567
        },
        "outputId": "3a77707d-2e10-4477-a233-0c2968765927",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521011319730,
          "user_tz": 420,
          "elapsed": 4467964,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Training across all subjects\n",
        "\n",
        "display_step = 15 \n",
        "\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "    for epoch in range(training_epochs):\n",
        "        for b in range(total_batches):    \n",
        "            offset = (b * batch_size) % (y_train.shape[0] - batch_size)\n",
        "            batch_x = X_train[offset:(offset + batch_size), :]\n",
        "            batch_y = y_train[offset:(offset + batch_size), :]\n",
        "            batch_y_steps = np.tile(batch_y,((X_train.shape[1]),1))\n",
        "            \n",
        "            _, acc, loss = session.run([optimizer, accuracy, loss_function], feed_dict={\n",
        "                x: batch_x, y: batch_y, y_steps: batch_y_steps, dropout: 0.3})\n",
        "            \n",
        "            if (b % display_step == 0):\n",
        "                print('training accuracy = %.2f, training loss = %f' % (acc, loss))\n",
        "            \n",
        "        test_accuracy = session.run(accuracy, feed_dict={\n",
        "            x:X_test, y:y_test, y_steps: y_test_steps, dropout: 0})\n",
        "        print('Epoch %d: test accuracy = %f' % (epoch, test_accuracy))\n",
        "            \n",
        "    "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy = 0.17, training loss = 1.177835\n",
            "training accuracy = 0.29, training loss = 1.157749\n",
            "training accuracy = 0.20, training loss = 1.133192\n",
            "training accuracy = 0.29, training loss = 1.077551\n",
            "Epoch 0: test accuracy = 0.244141\n",
            "training accuracy = 0.00, training loss = 1.041223\n",
            "training accuracy = 0.29, training loss = 0.994378\n",
            "training accuracy = 0.26, training loss = 0.980977\n",
            "training accuracy = 0.26, training loss = 0.966106\n",
            "Epoch 1: test accuracy = 0.244141\n",
            "training accuracy = 0.20, training loss = 0.973138\n",
            "training accuracy = 0.14, training loss = 0.951133\n",
            "training accuracy = 0.26, training loss = 0.941801\n",
            "training accuracy = 0.20, training loss = 0.927961\n",
            "Epoch 2: test accuracy = 0.244141\n",
            "training accuracy = 0.29, training loss = 0.910603\n",
            "training accuracy = 0.31, training loss = 0.908740\n",
            "training accuracy = 0.23, training loss = 0.897314\n",
            "training accuracy = 0.26, training loss = 0.889641\n",
            "Epoch 3: test accuracy = 0.244141\n",
            "training accuracy = 0.17, training loss = 0.893043\n",
            "training accuracy = 0.17, training loss = 0.875047\n",
            "training accuracy = 0.26, training loss = 0.864781\n",
            "training accuracy = 0.37, training loss = 0.848889\n",
            "Epoch 4: test accuracy = 0.244141\n",
            "training accuracy = 0.17, training loss = 0.855406\n",
            "training accuracy = 0.29, training loss = 0.841165\n",
            "training accuracy = 0.34, training loss = 0.836759\n",
            "training accuracy = 0.37, training loss = 0.826125\n",
            "Epoch 5: test accuracy = 0.244141\n",
            "training accuracy = 0.23, training loss = 0.826475\n",
            "training accuracy = 0.20, training loss = 0.815598\n",
            "training accuracy = 0.34, training loss = 0.807964\n",
            "training accuracy = 0.23, training loss = 0.804349\n",
            "Epoch 6: test accuracy = 0.244141\n",
            "training accuracy = 0.20, training loss = 0.798557\n",
            "training accuracy = 0.23, training loss = 0.789302\n",
            "training accuracy = 0.26, training loss = 0.789400\n",
            "training accuracy = 0.23, training loss = 0.775453\n",
            "Epoch 7: test accuracy = 0.244141\n",
            "training accuracy = 0.26, training loss = 0.771187\n",
            "training accuracy = 0.23, training loss = 0.768218\n",
            "training accuracy = 0.26, training loss = 0.762920\n",
            "training accuracy = 0.29, training loss = 0.752557\n",
            "Epoch 8: test accuracy = 0.244141\n",
            "training accuracy = 0.26, training loss = 0.750155\n",
            "training accuracy = 0.29, training loss = 0.740700\n",
            "training accuracy = 0.23, training loss = 0.740209\n",
            "training accuracy = 0.20, training loss = 0.735500\n",
            "Epoch 9: test accuracy = 0.244141\n",
            "training accuracy = 0.23, training loss = 0.737353\n",
            "training accuracy = 0.31, training loss = 0.730264\n",
            "training accuracy = 0.23, training loss = 0.721011\n",
            "training accuracy = 0.26, training loss = 0.715325\n",
            "Epoch 10: test accuracy = 0.244141\n",
            "training accuracy = 0.17, training loss = 0.720178\n",
            "training accuracy = 0.29, training loss = 0.706965\n",
            "training accuracy = 0.26, training loss = 0.707673\n",
            "training accuracy = 0.26, training loss = 0.702140\n",
            "Epoch 11: test accuracy = 0.244141\n",
            "training accuracy = 0.26, training loss = 0.697754\n",
            "training accuracy = 0.23, training loss = 0.695646\n",
            "training accuracy = 0.34, training loss = 0.694376\n",
            "training accuracy = 0.26, training loss = 0.693016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12: test accuracy = 0.255859\n",
            "training accuracy = 0.23, training loss = 0.686812\n",
            "training accuracy = 0.40, training loss = 0.678259\n",
            "training accuracy = 0.17, training loss = 0.683847\n",
            "training accuracy = 0.31, training loss = 0.671566\n",
            "Epoch 13: test accuracy = 0.255859\n",
            "training accuracy = 0.29, training loss = 0.672825\n",
            "training accuracy = 0.11, training loss = 0.675848\n",
            "training accuracy = 0.20, training loss = 0.671636\n",
            "training accuracy = 0.29, training loss = 0.658352\n",
            "Epoch 14: test accuracy = 0.238281\n",
            "training accuracy = 0.17, training loss = 0.674203\n",
            "training accuracy = 0.17, training loss = 0.660951\n",
            "training accuracy = 0.17, training loss = 0.661977\n",
            "training accuracy = 0.43, training loss = 0.649511\n",
            "Epoch 15: test accuracy = 0.238281\n",
            "training accuracy = 0.43, training loss = 0.649765\n",
            "training accuracy = 0.31, training loss = 0.649991\n",
            "training accuracy = 0.23, training loss = 0.653788\n",
            "training accuracy = 0.37, training loss = 0.638804\n",
            "Epoch 16: test accuracy = 0.238281\n",
            "training accuracy = 0.34, training loss = 0.641406\n",
            "training accuracy = 0.31, training loss = 0.640404\n",
            "training accuracy = 0.46, training loss = 0.639251\n",
            "training accuracy = 0.26, training loss = 0.639703\n",
            "Epoch 17: test accuracy = 0.238281\n",
            "training accuracy = 0.17, training loss = 0.637713\n",
            "training accuracy = 0.34, training loss = 0.636652\n",
            "training accuracy = 0.14, training loss = 0.635304\n",
            "training accuracy = 0.23, training loss = 0.633959\n",
            "Epoch 18: test accuracy = 0.238281\n",
            "training accuracy = 0.20, training loss = 0.635924\n",
            "training accuracy = 0.26, training loss = 0.626271\n",
            "training accuracy = 0.14, training loss = 0.630000\n",
            "training accuracy = 0.14, training loss = 0.627282\n",
            "Epoch 19: test accuracy = 0.238281\n",
            "training accuracy = 0.23, training loss = 0.623584\n",
            "training accuracy = 0.26, training loss = 0.618831\n",
            "training accuracy = 0.37, training loss = 0.616379\n",
            "training accuracy = 0.31, training loss = 0.615473\n",
            "Epoch 20: test accuracy = 0.238281\n",
            "training accuracy = 0.37, training loss = 0.615549\n",
            "training accuracy = 0.23, training loss = 0.618220\n",
            "training accuracy = 0.26, training loss = 0.616323\n",
            "training accuracy = 0.23, training loss = 0.614312\n",
            "Epoch 21: test accuracy = 0.238281\n",
            "training accuracy = 0.31, training loss = 0.613550\n",
            "training accuracy = 0.23, training loss = 0.614726\n",
            "training accuracy = 0.29, training loss = 0.606848\n",
            "training accuracy = 0.23, training loss = 0.607432\n",
            "Epoch 22: test accuracy = 0.238281\n",
            "training accuracy = 0.31, training loss = 0.608614\n",
            "training accuracy = 0.20, training loss = 0.610155\n",
            "training accuracy = 0.23, training loss = 0.608753\n",
            "training accuracy = 0.20, training loss = 0.608125\n",
            "Epoch 23: test accuracy = 0.238281\n",
            "training accuracy = 0.37, training loss = 0.602048\n",
            "training accuracy = 0.26, training loss = 0.603890\n",
            "training accuracy = 0.26, training loss = 0.603584\n",
            "training accuracy = 0.37, training loss = 0.601949\n",
            "Epoch 24: test accuracy = 0.238281\n",
            "training accuracy = 0.29, training loss = 0.601178\n",
            "training accuracy = 0.20, training loss = 0.602692\n",
            "training accuracy = 0.20, training loss = 0.602398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy = 0.23, training loss = 0.601588\n",
            "Epoch 25: test accuracy = 0.238281\n",
            "training accuracy = 0.23, training loss = 0.601891\n",
            "training accuracy = 0.34, training loss = 0.596790\n",
            "training accuracy = 0.17, training loss = 0.599117\n",
            "training accuracy = 0.51, training loss = 0.592210\n",
            "Epoch 26: test accuracy = 0.238281\n",
            "training accuracy = 0.17, training loss = 0.598652\n",
            "training accuracy = 0.23, training loss = 0.595620\n",
            "training accuracy = 0.31, training loss = 0.594115\n",
            "training accuracy = 0.29, training loss = 0.593212\n",
            "Epoch 27: test accuracy = 0.238281\n",
            "training accuracy = 0.23, training loss = 0.593503\n",
            "training accuracy = 0.29, training loss = 0.592939\n",
            "training accuracy = 0.37, training loss = 0.590249\n",
            "training accuracy = 0.26, training loss = 0.594391\n",
            "Epoch 28: test accuracy = 0.238281\n",
            "training accuracy = 0.17, training loss = 0.591991\n",
            "training accuracy = 0.20, training loss = 0.592266\n",
            "training accuracy = 0.17, training loss = 0.591866\n",
            "training accuracy = 0.20, training loss = 0.592326\n",
            "Epoch 29: test accuracy = 0.238281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LfTWskl-pbQR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 55
            },
            {
              "item_id": 110
            },
            {
              "item_id": 164
            },
            {
              "item_id": 219
            },
            {
              "item_id": 274
            },
            {
              "item_id": 329
            },
            {
              "item_id": 384
            },
            {
              "item_id": 439
            },
            {
              "item_id": 494
            },
            {
              "item_id": 539
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 9197
        },
        "outputId": "c738fe29-9268-4bde-bca3-a50eb4fd4f15",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521002731405,
          "user_tz": 420,
          "elapsed": 1325884,
          "user": {
            "displayName": "XUEYIN YU",
            "photoUrl": "//lh4.googleusercontent.com/-lIG2bWt6nOo/AAAAAAAAAAI/AAAAAAAAAB4/IuLOU1RLPtM/s50-c-k-no/photo.jpg",
            "userId": "110132106718146788609"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Training within each subject\n",
        "\n",
        "sub_num = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "#sub_num = [1]\n",
        "\n",
        "display_step_sub = 3\n",
        "\n",
        "for i in sub_num:\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        tf.global_variables_initializer().run()\n",
        "        for epoch in range(training_epochs_sub):\n",
        "            for b in range(total_batches_sub):    \n",
        "                offset = (b * batch_size_sub) % (y_train_sub[i-1].shape[0] - batch_size_sub)\n",
        "                batch_x = X_train_sub[i-1][offset:(offset + batch_size_sub), :]\n",
        "                batch_y = y_train_sub[i-1][offset:(offset + batch_size_sub), :]\n",
        "                batch_y_steps = np.tile(batch_y,((X_train_sub[i-1].shape[1]),1))\n",
        "                \n",
        "                _, acc, loss = session.run([optimizer, accuracy, loss_function], feed_dict={\n",
        "                    x: batch_x, y: batch_y, y_steps: batch_y_steps, dropout: 0.3})\n",
        "                \n",
        "                if (b % display_step_sub == 0):\n",
        "                    print('For subject %d : training accuracy = %.2f, training loss = %f' % (i, acc, loss))\n",
        "\n",
        "            test_accuracy = session.run(accuracy, feed_dict={\n",
        "                x:X_test_sub[i-1], y:y_test_sub[i-1], y_steps: y_test_steps_sub[i-1], dropout: 0})\n",
        "            print('For subject %d, Epoch %d: test accuracy = %f' % (i, epoch, test_accuracy))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For subject 1 : training accuracy = 0.33, training loss = 1.773301\n",
            "For subject 1 : training accuracy = 0.13, training loss = 1.726514\n",
            "For subject 1 : training accuracy = 0.20, training loss = 1.698125\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.660046\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.618992\n",
            "For subject 1, Epoch 0: test accuracy = 0.220000\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.587766\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.507805\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.507824\n",
            "For subject 1 : training accuracy = 0.40, training loss = 1.467749\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.451481\n",
            "For subject 1, Epoch 1: test accuracy = 0.220000\n",
            "For subject 1 : training accuracy = 0.13, training loss = 1.418364\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.361368\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.351876\n",
            "For subject 1 : training accuracy = 0.47, training loss = 1.304449\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.311927\n",
            "For subject 1, Epoch 2: test accuracy = 0.240000\n",
            "For subject 1 : training accuracy = 0.20, training loss = 1.306802\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.263142\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.256073\n",
            "For subject 1 : training accuracy = 0.67, training loss = 1.210832\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.218755\n",
            "For subject 1, Epoch 3: test accuracy = 0.260000\n",
            "For subject 1 : training accuracy = 0.20, training loss = 1.214986\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.183402\n",
            "For subject 1 : training accuracy = 0.47, training loss = 1.151873\n",
            "For subject 1 : training accuracy = 0.40, training loss = 1.133417\n",
            "For subject 1 : training accuracy = 0.47, training loss = 1.135056\n",
            "For subject 1, Epoch 4: test accuracy = 0.220000\n",
            "For subject 1 : training accuracy = 0.40, training loss = 1.126142\n",
            "For subject 1 : training accuracy = 0.27, training loss = 1.097222\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.073639\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.065360\n",
            "For subject 1 : training accuracy = 0.40, training loss = 1.059001\n",
            "For subject 1, Epoch 5: test accuracy = 0.220000\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.054718\n",
            "For subject 1 : training accuracy = 0.47, training loss = 1.015110\n",
            "For subject 1 : training accuracy = 0.40, training loss = 1.010432\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.005086\n",
            "For subject 1 : training accuracy = 0.33, training loss = 1.002136\n",
            "For subject 1, Epoch 6: test accuracy = 0.240000\n",
            "For subject 1 : training accuracy = 0.07, training loss = 1.011293\n",
            "For subject 1 : training accuracy = 0.47, training loss = 0.963952\n",
            "For subject 1 : training accuracy = 0.33, training loss = 0.966717\n",
            "For subject 1 : training accuracy = 0.53, training loss = 0.935720\n",
            "For subject 1 : training accuracy = 0.40, training loss = 0.940091\n",
            "For subject 1, Epoch 7: test accuracy = 0.240000\n",
            "For subject 1 : training accuracy = 0.20, training loss = 0.937621\n",
            "For subject 1 : training accuracy = 0.40, training loss = 0.909972\n",
            "For subject 1 : training accuracy = 0.53, training loss = 0.903003\n",
            "For subject 1 : training accuracy = 0.47, training loss = 0.896487\n",
            "For subject 1 : training accuracy = 0.60, training loss = 0.893383\n",
            "For subject 1, Epoch 8: test accuracy = 0.280000\n",
            "For subject 1 : training accuracy = 0.13, training loss = 0.891376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 1 : training accuracy = 0.20, training loss = 0.881302\n",
            "For subject 1 : training accuracy = 0.53, training loss = 0.853499\n",
            "For subject 1 : training accuracy = 0.53, training loss = 0.849175\n",
            "For subject 1 : training accuracy = 0.27, training loss = 0.854439\n",
            "For subject 1, Epoch 9: test accuracy = 0.240000\n",
            "For subject 2 : training accuracy = 0.13, training loss = 1.709210\n",
            "For subject 2 : training accuracy = 0.33, training loss = 1.657349\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.612431\n",
            "For subject 2 : training accuracy = 0.00, training loss = 1.606781\n",
            "For subject 2 : training accuracy = 0.47, training loss = 1.541178\n",
            "For subject 2, Epoch 0: test accuracy = 0.260000\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.498422\n",
            "For subject 2 : training accuracy = 0.33, training loss = 1.456198\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.411043\n",
            "For subject 2 : training accuracy = 0.20, training loss = 1.390569\n",
            "For subject 2 : training accuracy = 0.33, training loss = 1.338860\n",
            "For subject 2, Epoch 1: test accuracy = 0.300000\n",
            "For subject 2 : training accuracy = 0.20, training loss = 1.321565\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.299180\n",
            "For subject 2 : training accuracy = 0.13, training loss = 1.281542\n",
            "For subject 2 : training accuracy = 0.13, training loss = 1.258304\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.235754\n",
            "For subject 2, Epoch 2: test accuracy = 0.180000\n",
            "For subject 2 : training accuracy = 0.07, training loss = 1.227262\n",
            "For subject 2 : training accuracy = 0.13, training loss = 1.194995\n",
            "For subject 2 : training accuracy = 0.53, training loss = 1.167800\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.145848\n",
            "For subject 2 : training accuracy = 0.20, training loss = 1.143077\n",
            "For subject 2, Epoch 3: test accuracy = 0.220000\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.132971\n",
            "For subject 2 : training accuracy = 0.40, training loss = 1.103885\n",
            "For subject 2 : training accuracy = 0.40, training loss = 1.092442\n",
            "For subject 2 : training accuracy = 0.40, training loss = 1.069220\n",
            "For subject 2 : training accuracy = 0.27, training loss = 1.064273\n",
            "For subject 2, Epoch 4: test accuracy = 0.240000\n",
            "For subject 2 : training accuracy = 0.40, training loss = 1.059481\n",
            "For subject 2 : training accuracy = 0.47, training loss = 1.022454\n",
            "For subject 2 : training accuracy = 0.33, training loss = 1.008329\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.995486\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.990266\n",
            "For subject 2, Epoch 5: test accuracy = 0.260000\n",
            "For subject 2 : training accuracy = 0.20, training loss = 0.988532\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.973941\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.956685\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.929500\n",
            "For subject 2 : training accuracy = 0.47, training loss = 0.923192\n",
            "For subject 2, Epoch 6: test accuracy = 0.260000\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.926250\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.905507\n",
            "For subject 2 : training accuracy = 0.20, training loss = 0.913092\n",
            "For subject 2 : training accuracy = 0.20, training loss = 0.891595\n",
            "For subject 2 : training accuracy = 0.47, training loss = 0.871583\n",
            "For subject 2, Epoch 7: test accuracy = 0.300000\n",
            "For subject 2 : training accuracy = 0.20, training loss = 0.879310\n",
            "For subject 2 : training accuracy = 0.47, training loss = 0.855280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 2 : training accuracy = 0.33, training loss = 0.860406\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.836912\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.831908\n",
            "For subject 2, Epoch 8: test accuracy = 0.300000\n",
            "For subject 2 : training accuracy = 0.40, training loss = 0.831129\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.809819\n",
            "For subject 2 : training accuracy = 0.33, training loss = 0.823688\n",
            "For subject 2 : training accuracy = 0.53, training loss = 0.793543\n",
            "For subject 2 : training accuracy = 0.53, training loss = 0.800150\n",
            "For subject 2, Epoch 9: test accuracy = 0.280000\n",
            "For subject 3 : training accuracy = 0.27, training loss = 1.707825\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.669967\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.630469\n",
            "For subject 3 : training accuracy = 0.07, training loss = 1.615786\n",
            "For subject 3 : training accuracy = 0.13, training loss = 1.550590\n",
            "For subject 3, Epoch 0: test accuracy = 0.260000\n",
            "For subject 3 : training accuracy = 0.40, training loss = 1.503701\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.466719\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.428294\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.401275\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.352540\n",
            "For subject 3, Epoch 1: test accuracy = 0.240000\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.333611\n",
            "For subject 3 : training accuracy = 0.33, training loss = 1.307643\n",
            "For subject 3 : training accuracy = 0.07, training loss = 1.293494\n",
            "For subject 3 : training accuracy = 0.33, training loss = 1.269809\n",
            "For subject 3 : training accuracy = 0.13, training loss = 1.253843\n",
            "For subject 3, Epoch 2: test accuracy = 0.280000\n",
            "For subject 3 : training accuracy = 0.07, training loss = 1.238642\n",
            "For subject 3 : training accuracy = 0.47, training loss = 1.202592\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.186048\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.164542\n",
            "For subject 3 : training accuracy = 0.27, training loss = 1.153671\n",
            "For subject 3, Epoch 3: test accuracy = 0.380000\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.140619\n",
            "For subject 3 : training accuracy = 0.40, training loss = 1.119251\n",
            "For subject 3 : training accuracy = 0.33, training loss = 1.098958\n",
            "For subject 3 : training accuracy = 0.20, training loss = 1.095991\n",
            "For subject 3 : training accuracy = 0.33, training loss = 1.072749\n",
            "For subject 3, Epoch 4: test accuracy = 0.400000\n",
            "For subject 3 : training accuracy = 0.40, training loss = 1.049070\n",
            "For subject 3 : training accuracy = 0.27, training loss = 1.051314\n",
            "For subject 3 : training accuracy = 0.40, training loss = 1.028645\n",
            "For subject 3 : training accuracy = 0.40, training loss = 1.011328\n",
            "For subject 3 : training accuracy = 0.27, training loss = 1.008298\n",
            "For subject 3, Epoch 5: test accuracy = 0.380000\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.992176\n",
            "For subject 3 : training accuracy = 0.60, training loss = 0.972545\n",
            "For subject 3 : training accuracy = 0.27, training loss = 0.977298\n",
            "For subject 3 : training accuracy = 0.33, training loss = 0.953703\n",
            "For subject 3 : training accuracy = 0.20, training loss = 0.947781\n",
            "For subject 3, Epoch 6: test accuracy = 0.400000\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.938373\n",
            "For subject 3 : training accuracy = 0.47, training loss = 0.910193\n",
            "For subject 3 : training accuracy = 0.33, training loss = 0.918633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 3 : training accuracy = 0.33, training loss = 0.905249\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.898200\n",
            "For subject 3, Epoch 7: test accuracy = 0.420000\n",
            "For subject 3 : training accuracy = 0.27, training loss = 0.881635\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.862780\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.870773\n",
            "For subject 3 : training accuracy = 0.47, training loss = 0.846056\n",
            "For subject 3 : training accuracy = 0.27, training loss = 0.861581\n",
            "For subject 3, Epoch 8: test accuracy = 0.400000\n",
            "For subject 3 : training accuracy = 0.33, training loss = 0.843329\n",
            "For subject 3 : training accuracy = 0.47, training loss = 0.833338\n",
            "For subject 3 : training accuracy = 0.20, training loss = 0.822993\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.816996\n",
            "For subject 3 : training accuracy = 0.40, training loss = 0.818115\n",
            "For subject 3, Epoch 9: test accuracy = 0.360000\n",
            "For subject 4 : training accuracy = 0.33, training loss = 1.751422\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.712395\n",
            "For subject 4 : training accuracy = 0.07, training loss = 1.686180\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.637967\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.591846\n",
            "For subject 4, Epoch 0: test accuracy = 0.300000\n",
            "For subject 4 : training accuracy = 0.33, training loss = 1.535861\n",
            "For subject 4 : training accuracy = 0.40, training loss = 1.503789\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.474849\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.428044\n",
            "For subject 4 : training accuracy = 0.27, training loss = 1.389270\n",
            "For subject 4, Epoch 1: test accuracy = 0.220000\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.375195\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.361075\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.344758\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.323941\n",
            "For subject 4 : training accuracy = 0.47, training loss = 1.277578\n",
            "For subject 4, Epoch 2: test accuracy = 0.300000\n",
            "For subject 4 : training accuracy = 0.33, training loss = 1.266451\n",
            "For subject 4 : training accuracy = 0.47, training loss = 1.244399\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.224824\n",
            "For subject 4 : training accuracy = 0.27, training loss = 1.234697\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.210339\n",
            "For subject 4, Epoch 3: test accuracy = 0.300000\n",
            "For subject 4 : training accuracy = 0.27, training loss = 1.170330\n",
            "For subject 4 : training accuracy = 0.07, training loss = 1.180974\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.139666\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.141851\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.122362\n",
            "For subject 4, Epoch 4: test accuracy = 0.340000\n",
            "For subject 4 : training accuracy = 0.40, training loss = 1.094748\n",
            "For subject 4 : training accuracy = 0.27, training loss = 1.084520\n",
            "For subject 4 : training accuracy = 0.47, training loss = 1.064649\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.063392\n",
            "For subject 4 : training accuracy = 0.20, training loss = 1.043296\n",
            "For subject 4, Epoch 5: test accuracy = 0.320000\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.033207\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.021121\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.008940\n",
            "For subject 4 : training accuracy = 0.13, training loss = 1.002889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 4 : training accuracy = 0.13, training loss = 0.982140\n",
            "For subject 4, Epoch 6: test accuracy = 0.320000\n",
            "For subject 4 : training accuracy = 0.40, training loss = 0.967833\n",
            "For subject 4 : training accuracy = 0.27, training loss = 0.963097\n",
            "For subject 4 : training accuracy = 0.40, training loss = 0.942683\n",
            "For subject 4 : training accuracy = 0.20, training loss = 0.943654\n",
            "For subject 4 : training accuracy = 0.20, training loss = 0.930178\n",
            "For subject 4, Epoch 7: test accuracy = 0.300000\n",
            "For subject 4 : training accuracy = 0.33, training loss = 0.922444\n",
            "For subject 4 : training accuracy = 0.20, training loss = 0.907017\n",
            "For subject 4 : training accuracy = 0.47, training loss = 0.891554\n",
            "For subject 4 : training accuracy = 0.07, training loss = 0.906838\n",
            "For subject 4 : training accuracy = 0.40, training loss = 0.879285\n",
            "For subject 4, Epoch 8: test accuracy = 0.300000\n",
            "For subject 4 : training accuracy = 0.33, training loss = 0.887144\n",
            "For subject 4 : training accuracy = 0.40, training loss = 0.855734\n",
            "For subject 4 : training accuracy = 0.40, training loss = 0.845295\n",
            "For subject 4 : training accuracy = 0.20, training loss = 0.854176\n",
            "For subject 4 : training accuracy = 0.20, training loss = 0.843854\n",
            "For subject 4, Epoch 9: test accuracy = 0.340000\n",
            "For subject 5 : training accuracy = 0.07, training loss = 1.783850\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.736879\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.699346\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.654883\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.604571\n",
            "For subject 5, Epoch 0: test accuracy = 0.320000\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.564124\n",
            "For subject 5 : training accuracy = 0.40, training loss = 1.525983\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.508042\n",
            "For subject 5 : training accuracy = 0.33, training loss = 1.453124\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.429713\n",
            "For subject 5, Epoch 1: test accuracy = 0.260000\n",
            "For subject 5 : training accuracy = 0.33, training loss = 1.394663\n",
            "For subject 5 : training accuracy = 0.33, training loss = 1.358890\n",
            "For subject 5 : training accuracy = 0.13, training loss = 1.359378\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.328576\n",
            "For subject 5 : training accuracy = 0.47, training loss = 1.294470\n",
            "For subject 5, Epoch 2: test accuracy = 0.300000\n",
            "For subject 5 : training accuracy = 0.40, training loss = 1.271862\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.275513\n",
            "For subject 5 : training accuracy = 0.40, training loss = 1.255438\n",
            "For subject 5 : training accuracy = 0.33, training loss = 1.237613\n",
            "For subject 5 : training accuracy = 0.33, training loss = 1.206658\n",
            "For subject 5, Epoch 3: test accuracy = 0.260000\n",
            "For subject 5 : training accuracy = 0.13, training loss = 1.188613\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.173195\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.160882\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.140686\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.119676\n",
            "For subject 5, Epoch 4: test accuracy = 0.340000\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.120797\n",
            "For subject 5 : training accuracy = 0.13, training loss = 1.107505\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.091664\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.076036\n",
            "For subject 5 : training accuracy = 0.40, training loss = 1.043130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 5, Epoch 5: test accuracy = 0.360000\n",
            "For subject 5 : training accuracy = 0.40, training loss = 1.030113\n",
            "For subject 5 : training accuracy = 0.27, training loss = 1.033421\n",
            "For subject 5 : training accuracy = 0.20, training loss = 1.040413\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.991532\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.988204\n",
            "For subject 5, Epoch 6: test accuracy = 0.320000\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.969005\n",
            "For subject 5 : training accuracy = 0.20, training loss = 0.979184\n",
            "For subject 5 : training accuracy = 0.20, training loss = 0.959076\n",
            "For subject 5 : training accuracy = 0.53, training loss = 0.942517\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.946372\n",
            "For subject 5, Epoch 7: test accuracy = 0.300000\n",
            "For subject 5 : training accuracy = 0.20, training loss = 0.926266\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.917445\n",
            "For subject 5 : training accuracy = 0.27, training loss = 0.920419\n",
            "For subject 5 : training accuracy = 0.20, training loss = 0.901293\n",
            "For subject 5 : training accuracy = 0.27, training loss = 0.893322\n",
            "For subject 5, Epoch 8: test accuracy = 0.280000\n",
            "For subject 5 : training accuracy = 0.47, training loss = 0.867082\n",
            "For subject 5 : training accuracy = 0.27, training loss = 0.875588\n",
            "For subject 5 : training accuracy = 0.13, training loss = 0.860847\n",
            "For subject 5 : training accuracy = 0.33, training loss = 0.850796\n",
            "For subject 5 : training accuracy = 0.27, training loss = 0.849664\n",
            "For subject 5, Epoch 9: test accuracy = 0.320000\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.699566\n",
            "For subject 6 : training accuracy = 0.13, training loss = 1.645840\n",
            "For subject 6 : training accuracy = 0.20, training loss = 1.615567\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.558494\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.525656\n",
            "For subject 6, Epoch 0: test accuracy = 0.300000\n",
            "For subject 6 : training accuracy = 0.53, training loss = 1.467394\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.449324\n",
            "For subject 6 : training accuracy = 0.27, training loss = 1.405337\n",
            "For subject 6 : training accuracy = 0.20, training loss = 1.378688\n",
            "For subject 6 : training accuracy = 0.47, training loss = 1.330487\n",
            "For subject 6, Epoch 1: test accuracy = 0.240000\n",
            "For subject 6 : training accuracy = 0.40, training loss = 1.302068\n",
            "For subject 6 : training accuracy = 0.20, training loss = 1.304382\n",
            "For subject 6 : training accuracy = 0.27, training loss = 1.296947\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.251123\n",
            "For subject 6 : training accuracy = 0.40, training loss = 1.236870\n",
            "For subject 6, Epoch 2: test accuracy = 0.260000\n",
            "For subject 6 : training accuracy = 0.27, training loss = 1.217646\n",
            "For subject 6 : training accuracy = 0.47, training loss = 1.192119\n",
            "For subject 6 : training accuracy = 0.40, training loss = 1.173799\n",
            "For subject 6 : training accuracy = 0.47, training loss = 1.154274\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.147039\n",
            "For subject 6, Epoch 3: test accuracy = 0.260000\n",
            "For subject 6 : training accuracy = 0.53, training loss = 1.121027\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.114075\n",
            "For subject 6 : training accuracy = 0.27, training loss = 1.099452\n",
            "For subject 6 : training accuracy = 0.47, training loss = 1.071403\n",
            "For subject 6 : training accuracy = 0.40, training loss = 1.065881\n",
            "For subject 6, Epoch 4: test accuracy = 0.260000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 6 : training accuracy = 0.47, training loss = 1.051718\n",
            "For subject 6 : training accuracy = 0.33, training loss = 1.039658\n",
            "For subject 6 : training accuracy = 0.60, training loss = 1.002065\n",
            "For subject 6 : training accuracy = 0.47, training loss = 0.999678\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.999760\n",
            "For subject 6, Epoch 5: test accuracy = 0.260000\n",
            "For subject 6 : training accuracy = 0.27, training loss = 0.990964\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.978792\n",
            "For subject 6 : training accuracy = 0.33, training loss = 0.964881\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.941346\n",
            "For subject 6 : training accuracy = 0.33, training loss = 0.945028\n",
            "For subject 6, Epoch 6: test accuracy = 0.260000\n",
            "For subject 6 : training accuracy = 0.47, training loss = 0.916066\n",
            "For subject 6 : training accuracy = 0.27, training loss = 0.935764\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.909321\n",
            "For subject 6 : training accuracy = 0.47, training loss = 0.902377\n",
            "For subject 6 : training accuracy = 0.53, training loss = 0.875215\n",
            "For subject 6, Epoch 7: test accuracy = 0.240000\n",
            "For subject 6 : training accuracy = 0.53, training loss = 0.873203\n",
            "For subject 6 : training accuracy = 0.33, training loss = 0.882369\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.860162\n",
            "For subject 6 : training accuracy = 0.53, training loss = 0.835227\n",
            "For subject 6 : training accuracy = 0.27, training loss = 0.831882\n",
            "For subject 6, Epoch 8: test accuracy = 0.240000\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.832143\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.833142\n",
            "For subject 6 : training accuracy = 0.40, training loss = 0.816261\n",
            "For subject 6 : training accuracy = 0.60, training loss = 0.814848\n",
            "For subject 6 : training accuracy = 0.53, training loss = 0.799519\n",
            "For subject 6, Epoch 9: test accuracy = 0.260000\n",
            "For subject 7 : training accuracy = 0.13, training loss = 1.693632\n",
            "For subject 7 : training accuracy = 0.00, training loss = 1.669757\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.610944\n",
            "For subject 7 : training accuracy = 0.20, training loss = 1.575648\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.537481\n",
            "For subject 7, Epoch 0: test accuracy = 0.320000\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.492768\n",
            "For subject 7 : training accuracy = 0.13, training loss = 1.467720\n",
            "For subject 7 : training accuracy = 0.27, training loss = 1.424146\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.370558\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.331680\n",
            "For subject 7, Epoch 1: test accuracy = 0.240000\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.316837\n",
            "For subject 7 : training accuracy = 0.13, training loss = 1.320316\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.286591\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.269017\n",
            "For subject 7 : training accuracy = 0.60, training loss = 1.221505\n",
            "For subject 7, Epoch 2: test accuracy = 0.280000\n",
            "For subject 7 : training accuracy = 0.27, training loss = 1.232168\n",
            "For subject 7 : training accuracy = 0.20, training loss = 1.211179\n",
            "For subject 7 : training accuracy = 0.47, training loss = 1.165542\n",
            "For subject 7 : training accuracy = 0.27, training loss = 1.187402\n",
            "For subject 7 : training accuracy = 0.47, training loss = 1.144139\n",
            "For subject 7, Epoch 3: test accuracy = 0.300000\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.130407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 7 : training accuracy = 0.13, training loss = 1.140265\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.095043\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.092986\n",
            "For subject 7 : training accuracy = 0.40, training loss = 1.067327\n",
            "For subject 7, Epoch 4: test accuracy = 0.280000\n",
            "For subject 7 : training accuracy = 0.47, training loss = 1.050393\n",
            "For subject 7 : training accuracy = 0.27, training loss = 1.065185\n",
            "For subject 7 : training accuracy = 0.33, training loss = 1.029014\n",
            "For subject 7 : training accuracy = 0.07, training loss = 1.038504\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.994631\n",
            "For subject 7, Epoch 5: test accuracy = 0.320000\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.989919\n",
            "For subject 7 : training accuracy = 0.00, training loss = 1.010390\n",
            "For subject 7 : training accuracy = 0.53, training loss = 0.956251\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.955468\n",
            "For subject 7 : training accuracy = 0.40, training loss = 0.941933\n",
            "For subject 7, Epoch 6: test accuracy = 0.300000\n",
            "For subject 7 : training accuracy = 0.20, training loss = 0.941129\n",
            "For subject 7 : training accuracy = 0.07, training loss = 0.946715\n",
            "For subject 7 : training accuracy = 0.40, training loss = 0.908790\n",
            "For subject 7 : training accuracy = 0.27, training loss = 0.921374\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.895895\n",
            "For subject 7, Epoch 7: test accuracy = 0.340000\n",
            "For subject 7 : training accuracy = 0.20, training loss = 0.881319\n",
            "For subject 7 : training accuracy = 0.33, training loss = 0.887354\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.859291\n",
            "For subject 7 : training accuracy = 0.33, training loss = 0.871789\n",
            "For subject 7 : training accuracy = 0.33, training loss = 0.851847\n",
            "For subject 7, Epoch 8: test accuracy = 0.300000\n",
            "For subject 7 : training accuracy = 0.27, training loss = 0.840599\n",
            "For subject 7 : training accuracy = 0.40, training loss = 0.847641\n",
            "For subject 7 : training accuracy = 0.33, training loss = 0.824829\n",
            "For subject 7 : training accuracy = 0.40, training loss = 0.815731\n",
            "For subject 7 : training accuracy = 0.47, training loss = 0.808399\n",
            "For subject 7, Epoch 9: test accuracy = 0.340000\n",
            "For subject 8 : training accuracy = 0.13, training loss = 1.681038\n",
            "For subject 8 : training accuracy = 0.07, training loss = 1.641414\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.608785\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.557211\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.524383\n",
            "For subject 8, Epoch 0: test accuracy = 0.380000\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.480009\n",
            "For subject 8 : training accuracy = 0.47, training loss = 1.423208\n",
            "For subject 8 : training accuracy = 0.40, training loss = 1.398423\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.371010\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.324684\n",
            "For subject 8, Epoch 1: test accuracy = 0.360000\n",
            "For subject 8 : training accuracy = 0.40, training loss = 1.301594\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.284808\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.271472\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.251376\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.219333\n",
            "For subject 8, Epoch 2: test accuracy = 0.220000\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.214154\n",
            "For subject 8 : training accuracy = 0.40, training loss = 1.174167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 8 : training accuracy = 0.33, training loss = 1.166561\n",
            "For subject 8 : training accuracy = 0.13, training loss = 1.166468\n",
            "For subject 8 : training accuracy = 0.27, training loss = 1.130982\n",
            "For subject 8, Epoch 3: test accuracy = 0.260000\n",
            "For subject 8 : training accuracy = 0.53, training loss = 1.102225\n",
            "For subject 8 : training accuracy = 0.40, training loss = 1.082417\n",
            "For subject 8 : training accuracy = 0.47, training loss = 1.068055\n",
            "For subject 8 : training accuracy = 0.07, training loss = 1.077761\n",
            "For subject 8 : training accuracy = 0.20, training loss = 1.058654\n",
            "For subject 8, Epoch 4: test accuracy = 0.340000\n",
            "For subject 8 : training accuracy = 0.47, training loss = 1.026806\n",
            "For subject 8 : training accuracy = 0.40, training loss = 1.016895\n",
            "For subject 8 : training accuracy = 0.47, training loss = 0.996564\n",
            "For subject 8 : training accuracy = 0.13, training loss = 1.018199\n",
            "For subject 8 : training accuracy = 0.20, training loss = 0.995803\n",
            "For subject 8, Epoch 5: test accuracy = 0.320000\n",
            "For subject 8 : training accuracy = 0.67, training loss = 0.962424\n",
            "For subject 8 : training accuracy = 0.47, training loss = 0.950601\n",
            "For subject 8 : training accuracy = 0.53, training loss = 0.936796\n",
            "For subject 8 : training accuracy = 0.27, training loss = 0.949896\n",
            "For subject 8 : training accuracy = 0.40, training loss = 0.926598\n",
            "For subject 8, Epoch 6: test accuracy = 0.280000\n",
            "For subject 8 : training accuracy = 0.40, training loss = 0.919333\n",
            "For subject 8 : training accuracy = 0.73, training loss = 0.886688\n",
            "For subject 8 : training accuracy = 0.53, training loss = 0.884273\n",
            "For subject 8 : training accuracy = 0.13, training loss = 0.898964\n",
            "For subject 8 : training accuracy = 0.27, training loss = 0.886997\n",
            "For subject 8, Epoch 7: test accuracy = 0.300000\n",
            "For subject 8 : training accuracy = 0.47, training loss = 0.864315\n",
            "For subject 8 : training accuracy = 0.47, training loss = 0.844039\n",
            "For subject 8 : training accuracy = 0.47, training loss = 0.834443\n",
            "For subject 8 : training accuracy = 0.33, training loss = 0.847568\n",
            "For subject 8 : training accuracy = 0.13, training loss = 0.846009\n",
            "For subject 8, Epoch 8: test accuracy = 0.320000\n",
            "For subject 8 : training accuracy = 0.60, training loss = 0.814061\n",
            "For subject 8 : training accuracy = 0.27, training loss = 0.817324\n",
            "For subject 8 : training accuracy = 0.60, training loss = 0.791483\n",
            "For subject 8 : training accuracy = 0.27, training loss = 0.823134\n",
            "For subject 8 : training accuracy = 0.13, training loss = 0.818090\n",
            "For subject 8, Epoch 9: test accuracy = 0.340000\n",
            "For subject 9 : training accuracy = 0.20, training loss = 1.718675\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.673134\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.622589\n",
            "For subject 9 : training accuracy = 0.20, training loss = 1.608304\n",
            "For subject 9 : training accuracy = 0.40, training loss = 1.550763\n",
            "For subject 9, Epoch 0: test accuracy = 0.200000\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.503025\n",
            "For subject 9 : training accuracy = 0.53, training loss = 1.459906\n",
            "For subject 9 : training accuracy = 0.47, training loss = 1.422415\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.413975\n",
            "For subject 9 : training accuracy = 0.07, training loss = 1.365121\n",
            "For subject 9, Epoch 1: test accuracy = 0.260000\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.333529\n",
            "For subject 9 : training accuracy = 0.40, training loss = 1.310610\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.292449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "For subject 9 : training accuracy = 0.27, training loss = 1.292430\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.255715\n",
            "For subject 9, Epoch 2: test accuracy = 0.240000\n",
            "For subject 9 : training accuracy = 0.47, training loss = 1.222588\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.207095\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.205673\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.189424\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.163534\n",
            "For subject 9, Epoch 3: test accuracy = 0.220000\n",
            "For subject 9 : training accuracy = 0.47, training loss = 1.141999\n",
            "For subject 9 : training accuracy = 0.40, training loss = 1.127613\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.108346\n",
            "For subject 9 : training accuracy = 0.47, training loss = 1.105422\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.091610\n",
            "For subject 9, Epoch 4: test accuracy = 0.280000\n",
            "For subject 9 : training accuracy = 0.27, training loss = 1.073899\n",
            "For subject 9 : training accuracy = 0.53, training loss = 1.042100\n",
            "For subject 9 : training accuracy = 0.47, training loss = 1.036871\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.036600\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.024399\n",
            "For subject 9, Epoch 5: test accuracy = 0.260000\n",
            "For subject 9 : training accuracy = 0.33, training loss = 1.000187\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.978991\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.961823\n",
            "For subject 9 : training accuracy = 0.13, training loss = 0.988487\n",
            "For subject 9 : training accuracy = 0.47, training loss = 0.962157\n",
            "For subject 9, Epoch 6: test accuracy = 0.300000\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.925309\n",
            "For subject 9 : training accuracy = 0.53, training loss = 0.929657\n",
            "For subject 9 : training accuracy = 0.27, training loss = 0.924469\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.920416\n",
            "For subject 9 : training accuracy = 0.53, training loss = 0.904540\n",
            "For subject 9, Epoch 7: test accuracy = 0.280000\n",
            "For subject 9 : training accuracy = 0.53, training loss = 0.883086\n",
            "For subject 9 : training accuracy = 0.33, training loss = 0.874366\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.869821\n",
            "For subject 9 : training accuracy = 0.20, training loss = 0.876408\n",
            "For subject 9 : training accuracy = 0.33, training loss = 0.865421\n",
            "For subject 9, Epoch 8: test accuracy = 0.280000\n",
            "For subject 9 : training accuracy = 0.53, training loss = 0.837304\n",
            "For subject 9 : training accuracy = 0.27, training loss = 0.835920\n",
            "For subject 9 : training accuracy = 0.27, training loss = 0.838626\n",
            "For subject 9 : training accuracy = 0.33, training loss = 0.832311\n",
            "For subject 9 : training accuracy = 0.40, training loss = 0.821388\n",
            "For subject 9, Epoch 9: test accuracy = 0.260000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5P_yiByKv5t4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}